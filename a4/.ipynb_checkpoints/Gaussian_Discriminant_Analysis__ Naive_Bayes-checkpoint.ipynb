{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62ce930",
   "metadata": {},
   "source": [
    "Alohan'ny mamerina dia avereno atao Run ny notebook iray manontolo. Ny fanaovana azy dia red√©marrena mihitsy ny kernel aloha (jereo menubar, safidio **Kernel$\\rightarrow$Restart Kernel and Run All Cells**).\n",
    "\n",
    "Izay misy hoe `YOUR CODE HERE` na \"YOUR ANSWER HERE\" ihany no fenoina. Afaka manampy cells vaovao raha ilaina. Aza adino ny mameno references eo ambany raha ilaina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e868a8",
   "metadata": {},
   "source": [
    "## References\n",
    "Eto ilay references rehetra no apetraka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbff9b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e424e4",
   "metadata": {},
   "source": [
    "## DO NOT USE FOR LOOP ON number of samples N but ONLY ON number of classes C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4b0d2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5b3a9bb5f9459df46861b5d84bda38",
     "grade": false,
     "grade_id": "cell-f4572dec0c7469a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_digits\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39598113",
   "metadata": {},
   "source": [
    "# Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b03949",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19e957d3826dd3977f54f428a8744d6",
     "grade": false,
     "grade_id": "cell-d82471ddcebf7ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596068c6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5735812b7d43eb37d2bd53c84670597",
     "grade": false,
     "grade_id": "cell-212a715c4b2f4e77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_priors(X, y):\n",
    "    \"\"\"\n",
    "    Prior probability for each class \n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - priors : array of shape (C,)\n",
    "    \"\"\"\n",
    "    C = (np.max(y) + 1)\n",
    "    priors = np.zeros(C)\n",
    "    # YOUR CODE HERE\n",
    "    for c in range(C):\n",
    "        priors[c] = (y == c).sum() / X.shape[0]\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc84667",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4595f1d0682daf1d642222e34ca7546f",
     "grade": true,
     "grade_id": "cell-25707d195d3be37b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "priors = compute_priors(X_train, y_train)\n",
    "error = rel_error(sk_model.priors_, priors)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d5036a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80987a776d96e04af5c7a0922be6fc7b",
     "grade": false,
     "grade_id": "cell-a4f5a8d209b51a14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_means(X, y):\n",
    "    \"\"\"\n",
    "    Mean estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - means : array of shape (C, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    means = np.zeros((C, D))\n",
    "    # YOUR CODE HERE\n",
    "    for c in range(C):\n",
    "        means[c] = (X[(y==c)].sum(axis=0)) / len(X[y==c])\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39aebd0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5139bd849307229ab94c6dc869516b",
     "grade": true,
     "grade_id": "cell-1ea0c5a7199f1d21",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "means = compute_means(X_train, y_train)\n",
    "error = rel_error(sk_model.means_, means)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f43ffa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d440cdafa2d4b166c5220793a35fcf7",
     "grade": false,
     "grade_id": "cell-f1401a628db797ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigmas_gda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariances : array of shape (C, D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariances = np.zeros((C, D, D))\n",
    "    # YOUR CODE HERE\n",
    "    # cov_c = (1 / N_c) * Sum_ (X - mean(X))(X - mean(X)).T\n",
    "    for c in range(C):\n",
    "        X_centered = X[y==c] - np.full((X[y==c].shape[0], X[y==c].shape[1]), means[c])\n",
    "        covariances[c] = (X_centered.T.dot(X_centered)) / (len(X[y==c]) - 1)\n",
    "\n",
    "    return covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5a7f7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a27ecc6bbc72e72cfebaffd3ede565",
     "grade": true,
     "grade_id": "cell-6b136fdb522b6eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6754077962343515e-15\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigmas_gda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcf24c0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "824613ff0ad0e3acb8e67b499598fbba",
     "grade": false,
     "grade_id": "cell-9970ad744b99041a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigma_lda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for LDA, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariance : array of shape (D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariance = np.zeros((D, D))\n",
    "    # YOUR CODE HERE\n",
    "    # cov = (i / N) (sum_ ) (sum_ ) (X - mean)(X - mean).T\n",
    "    for c in range(C):\n",
    "        X_centered = X[y==c] - means[c]\n",
    "        covariance += (X_centered.T.dot(X_centered))\n",
    "        \n",
    "    covariance /= len(X)\n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e4bfa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a95472e963297e49709fc0b8c212e341",
     "grade": true,
     "grade_id": "cell-686b35c7c584416e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0687223965233616e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigma_lda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84312aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b0c0ed8697c9ae414131f3918c0037",
     "grade": false,
     "grade_id": "cell-17c0ce2515e2fc7c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_lda(X, C, priors, means, covariance):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariance : array of shape (D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    W = np.zeros((C,D))\n",
    "    b = np.zeros(C)\n",
    "    # YOUR CODE HERE\n",
    "    # log = a_c + x.T b_c + cst\n",
    "    for c in range(C):\n",
    "        # a_c = np.log(priors[c]) - (1/2) * means[c].dot(np.linalg.inv(covariance).dot(means[c]).T) \n",
    "        # b_c = X.dot(np.linalg.inv(covariance).dot(means[c]))\n",
    "        # cst = (1/2) * X.dot(np.linalg.inv(covariance).dot(X.T))\n",
    "        # log_posterior[:,c] = a_c + b_c - np.diag(cst)\n",
    "        X_centered = X - means[c]\n",
    "        log_posterior[:,c] = np.log(priors[c]) - (1/2) * np.diag(X_centered.dot(np.linalg.inv(covariance).dot(X_centered.T)))\n",
    "        \n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddec807",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb8777a126866cace4cb4d1b73225f5",
     "grade": false,
     "grade_id": "cell-7a43326dd032e8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NO TEST FOR LOG-POSTERIOR LDA. Mitambatra eo ambany ny test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2a8ee0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2ed41a12624f40c8eabd8a1bac44cb4",
     "grade": false,
     "grade_id": "cell-cc5e3a7eddeb02ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_gda(X, C, priors, means, covariances):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariances : array of shape (C, D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    # YOUR CODE HERE\n",
    "    for c in range(C):\n",
    "        X_centered = X - means[c]\n",
    "        a_c = np.log(priors[c]) - (1/2) * np.log(np.linalg.det(covariances[c])) \n",
    "        b_c = (1/2) * X_centered.dot(np.linalg.inv(covariances[c]).dot(X_centered.T))\n",
    "        log_posterior[:,c] = a_c - np.diag(b_c)\n",
    "\n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c38e381",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c0afab4af1700e0a0fc48dd1118bdd",
     "grade": true,
     "grade_id": "cell-d58bf74c60153098",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.089527276208008e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "C = (np.max(y_train) + 1)\n",
    "log_posterior = compute_log_posterior_gda(X_train, C, sk_model.priors_, sk_model.means_, sk_model.covariance_)\n",
    "error = rel_error(np.asarray(sk_model._decision_function(X_train)), log_posterior)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de0226f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea4a371e372fa034dcbf73d579c3358",
     "grade": false,
     "grade_id": "cell-f5cbad4c325e856e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbClassifier():\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        # YOUR CODE HERE\n",
    "        y_pred = np.argmax(log_post, axis=1)\n",
    "        return y_pred\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        # YOUR CODE HERE\n",
    "        p_1 = np.exp(log_posterior)\n",
    "        p_sum = np.exp(log_posterior).sum(axis=1)\n",
    "        p_sum = np.reshape(p_sum, (X.shape[0], 1))\n",
    "        return p_1 / p_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00619c96",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c234be9d70fd14a4551b6fcbf8de7ea5",
     "grade": false,
     "grade_id": "cell-1bbbe43fcaed8c4e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigma_lda(X, y, self.means)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        return compute_log_posterior_lda(X, self.C, self.priors, self.means, self.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad71564",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "470a4776ad0f7dd0fa6df62af2985724",
     "grade": true,
     "grade_id": "cell-103960c9425d1e47",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "pred = lda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8c6e3b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c02ef4c722a12c047cdd79a33b701bf",
     "grade": false,
     "grade_id": "cell-a86acf06e6c80728",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigmas_gda(X, y, self.means)\n",
    "        \n",
    "    def compute_log_posterior(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        return compute_log_posterior_gda(X, self.C, self.priors, self.means, self.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaceff8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e49782d08f05716006eaa10b9483f",
     "grade": true,
     "grade_id": "cell-407cb9988a114256",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e74ae0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7666654f5e7cfcd44a8c2dc0291c0ed9",
     "grade": true,
     "grade_id": "cell-1d95b01b2541d240",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1949395701722783e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict_proba(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict_proba(X_train)\n",
    "\n",
    "error = rel_error(pred, sk_pred)\n",
    "print(error)\n",
    "assert error < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17af43",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2639cfb",
   "metadata": {},
   "source": [
    "##  Bernouilli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87252e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X_train2, y_train2 = data.data, data.target\n",
    "X_train2_transf = Binarizer().fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04021ee0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70742cc3e580d8bfdbf0b9de07a87912",
     "grade": false,
     "grade_id": "cell-d5b51da0e0b8dcc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BernouilliNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.theta = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameter theta\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.theta = np.zeros((D, self.C))\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        for c in range(self.C):\n",
    "            N_dc = (X[y==c]).sum(axis=0)\n",
    "            self.theta[:,c] = N_dc / X[y==c].shape[0]\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        eps = 1e-15\n",
    "        a_c = X @ np.log(self.theta + eps)\n",
    "        b_c = (1 - X) @ np.log(1 - self.theta + eps)\n",
    "        log_post = np.log(self.priors) + a_c + b_c\n",
    "\n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a70e61a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa098602d1a9e4c9cdca9cf73180a44",
     "grade": true,
     "grade_id": "cell-f960b1ec2ce34b3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.8636616583194212\n",
      "Your Accuracy :  0.8742348358375069\n"
     ]
    }
   ],
   "source": [
    "sk_model = BernoulliNB()\n",
    "sk_model.fit(X_train2_transf, y_train2)\n",
    "sk_pred = sk_model.predict(X_train2_transf)\n",
    "\n",
    "model = BernouilliNaiveBayes()\n",
    "model.fit(X_train2_transf, y_train2)\n",
    "pred = model.predict(X_train2_transf)\n",
    "\n",
    "sk_acc = accuracy_score(y_train2, sk_pred)\n",
    "model_acc = accuracy_score(y_train2, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d8dc6",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99588c0d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d67f1b1383503b5e5203c265f59b99d",
     "grade": false,
     "grade_id": "cell-186f17a680895047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameters mu and sigma\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.sigma = np.zeros((D, self.C))\n",
    "        self.mu = np.zeros((D,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.mu = compute_means(X, y).T\n",
    "        for c in range(self.C):\n",
    "            X_centered = X[y==c] - self.mu[:,c]\n",
    "            self.sigma[:,c] = (1/X[y==c].shape[0]) * (X_centered**2).sum(axis=0)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        for c in range(C):\n",
    "            a_c = np.log(self.priors[c])\n",
    "            b_c = -(1/2) * np.sum( (((X-self.mu[:,c])**2 / self.sigma[:,c]) + np.log(2 * np.pi * (self.sigma[:,c]))), axis=1)\n",
    "            log_post[:,c] = a_c + b_c\n",
    "            \n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2072fea0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d510e4b6069f1d0549606f4a4a12416",
     "grade": true,
     "grade_id": "cell-7ac37952b1e80482",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.96\n",
      "Your Accuracy :  0.96\n"
     ]
    }
   ],
   "source": [
    "sk_model = GaussianNB()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "model = GaussianNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_train)\n",
    "\n",
    "sk_acc = accuracy_score(y_train, sk_pred)\n",
    "model_acc = accuracy_score(y_train, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ebeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
